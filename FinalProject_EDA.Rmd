---
title: "Final Project EDA"
author: "XI KANG, MINGZE YAN"
date: "4/25/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,  message = FALSE, warning = FALSE)
```

```{r load-packages-set-seed}
## Load Packages, Set Seed
library(tidyverse)
library(tidymodels)
library(skimr)
library(naniar)
library(kableExtra)
set.seed(123)
```

## Introduction

This is the EDA section for the Stat 301-3 final project. The goal of this project is to predict one's risk for stroke through a classification approach. 
<br>

Based on the information from the [World Health Organization (WHO)](https://dx.doi.org/10.2471/BLT.16.181636), stroke is the second leading cause of death and the third leading cause for disability. Nevertheless, effective prevention actions can be applied to reduce the fatal effects of this medical emergency and lower the risk for mortality and disability. Thus, to provide targeted support and effective prevention strategies, it is crucial to identify the risks for stroke based on common factors related to one's lifestyle or chronic health conditions. 
<br>

Thus, driven by the incentives mentioned above, our project focuses on predicting the risk for stroke based on input parameters about one's lifestyle and health status. The research question of this project is a predictive classification question. 
<br>

## Initial Overview

### Data Source

The dataset used by this project is the "Stroke Prediction Dataset" provided on [Kaggle](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset). We first loaded in the raw dataset and cleaned the names.  The initial data tidying process it completed in the FinalProject_tidy_data.r file. The code used is presented below:
```{r tidy-data, eval=FALSE}
## Load raw dataset ----
stroke_dat <- 
  read_csv("data/unprocessed/healthcare-dataset-stroke-data.csv") %>% 
  clean_names() %>% 
  mutate(
    gender = factor(gender), 
    ever_married = factor(ever_married),
    work_type = factor(work_type),
    residence_type = factor(residence_type),
    smoking_status = factor(smoking_status),
    stroke = factor(stroke, levels = c(1, 0), 
                    labels = c("Yes", "No")),
    hypertension = factor(hypertension, levels = c(1, 0), 
                          labels = c("Yes", "No")), 
    heart_disease = factor(heart_disease, levels = c(1, 0), 
                           labels = c("Yes", "No")), 
    bmi = as.numeric(bmi)
  ) %>% 
  select(-id)

## initial skimming ----
skim_without_charts(stroke_dat)

## save processed data ----
stroke_dat %>% 
  write_rds("data/processed/stroke_data.rds")
```
<br>

### Dataset Overview

Using methods from `skimr`, we noticed that the original dataset contains 5110 rows and 12 columns. For the convenience of the later processes, we first turned the categorical variables `gender`, `ever_married`, `work_type`, `residence_type`, and `smoking_status` into factors. The outcome variable `stroke` and variables `hypertension` and `heart_disease` were initially identified as numeric variables, but they should be categorical. Thus, we turned them into a factors. Since `id` will not be used as a categorical variable, we removed it from the original dataset. 
<br>

After initial tidying, we loaded in the processed data performed a train-test split, stratified by the outcome variable `stroke`. We used 70% of the data for training and 30% for testing: 
```{r, load-data-and-split}
stroke_data <- readRDS("data/processed/stroke_data.rds")

## split data ----
stroke_split <- initial_split(stroke_data, prop = 0.7, strata = stroke)
stroke_train <- training(stroke_split)
stroke_test <- testing(stroke_split)
```
<br>

The EDA section will be performed using the training set data, `stroke_train`.
<br>

After the split, we first obtained an overview on the training set using the methods from the `skimr` package. We noticed that the training set contains 11 variables, and 3577 observations. Among them 8 variables are factors and 3 variables are numeric. The outcome variable `stroke` is a categorical variable of type factor. 
<br>

### Missing Data

During the initial skimming, we noticed that only one variable `bmi` contains missing values. To obtain a wholistic overview on the general situation of missingness in the training data, we created a plot showing the amount of missing data in each column using the `vis_miss()` function from `naniar`: 
```{r, fig.height = 7, fig.width = 7}
# overview of missingness
stroke_train %>% 
  vis_miss(sort_miss = TRUE)
```
<br>

As shown, within the 11 columns in the dataset, there is only column `bmi` with missing data. The response variable `stroke` does not have any missing values. To clearly present the percentage of missingness for each variable, we created the table below using `miss_var_summary()`, and we highlighted the rows for the variable with missing value in blue:  
```{r}
# overview table
stroke_train %>% 
  miss_var_summary() %>% 
  kbl() %>% 
  kable_classic() %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  row_spec(1, color = "white",
           background = "blue") %>% 
  kableExtra::footnote(
    general = "Number and Percentage of Missing Values in Each Variable"
  )
```
<br>

As shown, `bmi` is the only variable with missing values and its percentage of missingness is about 4%. Since the degree of missingness is very low, we plan to impute `bmi` using bagged tree imputation. 
<br>

## Essential Findings

### Outcome Variable

## Secondary Findings

## Conclusion and Implications